{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae6120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "75488798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9c14f59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416804</th>\n",
       "      <td>that was what i felt when i was finally accept...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416805</th>\n",
       "      <td>i take every day as it comes i m just focussin...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416806</th>\n",
       "      <td>i just suddenly feel that everything was fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416807</th>\n",
       "      <td>im feeling more eager than ever to claw back w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416808</th>\n",
       "      <td>i give you plenty of attention even when i fee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416809 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "0       i feel awful about it too because it s my job ...      0\n",
       "1                                   im alone i feel awful      0\n",
       "2       ive probably mentioned this before but i reall...      1\n",
       "3                i was feeling a little low few days back      0\n",
       "4       i beleive that i am much more sensitive to oth...      2\n",
       "...                                                   ...    ...\n",
       "416804  that was what i felt when i was finally accept...      1\n",
       "416805  i take every day as it comes i m just focussin...      4\n",
       "416806      i just suddenly feel that everything was fake      0\n",
       "416807  im feeling more eager than ever to claw back w...      1\n",
       "416808  i give you plenty of attention even when i fee...      0\n",
       "\n",
       "[416809 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Dataset/emotion_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ac634782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[0:20000]\n",
    "column= 'text'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a908e784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANISH\\AppData\\Local\\Temp\\ipykernel_25752\\2706339257.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.lower()\n",
      "C:\\Users\\ANISH\\AppData\\Local\\Temp\\ipykernel_25752\\2706339257.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: remove_stopwords(x))\n",
      "C:\\Users\\ANISH\\AppData\\Local\\Temp\\ipykernel_25752\\2706339257.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: remove_splcharacters(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feel awful job get position succeed happen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone feel awful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned really feel proud actua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feeling little low days back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beleive much sensitive peoples feelings tend c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0         feel awful job get position succeed happen      0\n",
       "1                                im alone feel awful      0\n",
       "2  ive probably mentioned really feel proud actua...      1\n",
       "3                       feeling little low days back      0\n",
       "4  beleive much sensitive peoples feelings tend c...      2"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "df[column] = df[column].str.lower()\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in STOPWORDS])\n",
    "\n",
    "df[column] = df[column].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "def remove_splcharacters(text):\n",
    "    text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "df[column] = df[column].apply(lambda x: remove_splcharacters(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "640a9c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANISH\\AppData\\Local\\Temp\\ipykernel_25752\\3103777441.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: lemmatize_text(x))\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word, pos ='v') for word in text.split()])\n",
    "\n",
    "df[column] = df[column].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0781dd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13737"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df[column])\n",
    "\n",
    "\n",
    "import pickle\n",
    "# Save tokenizer\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bdf17e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,  367,  201, ...,    0,    0,    0],\n",
       "       [   3,  117,    1, ...,    0,    0,    0],\n",
       "       [  22,  214,  514, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   1, 1487,  448, ...,    0,    0,    0],\n",
       "       [ 138,    1,   17, ...,    0,    0,    0],\n",
       "       [   1,   26,  110, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding the data\n",
    "sequence = tokenizer.texts_to_sequences(df[column])\n",
    "\n",
    "# maximum length of the data\n",
    "max_len = 40\n",
    "padded_seq = pad_sequences(sequence,maxlen=max_len, padding='post', truncating= 'post')\n",
    "padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c9eb8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "\n",
    "#create embedding index\n",
    "embedding_index = {}\n",
    "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        embed_list = np.array(values[1:]).astype('float32')\n",
    "        embedding_index[word]= embed_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "700205c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create embedding matrix\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((vocab_size+1, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cc2cd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain,  xtest, ytrain,ytest = train_test_split(padded_seq,df['label'], train_size=0.9, random_state=42)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "ytrain = to_categorical(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4fb6a5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,373,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │     \u001b[38;5;34m1,373,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,373,800</span> (5.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,373,800\u001b[0m (5.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,373,800</span> (5.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,373,800\u001b[0m (5.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the model \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Embedding(\n",
    "        input_dim=vocab_size + 1,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_len,\n",
    "        trainable=False,  # freeze pretrained embeddings\n",
    "    )\n",
    ")\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "64a95bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.3343 - loss: 1.6103 - val_accuracy: 0.3278 - val_loss: 1.5923\n",
      "Epoch 2/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.3336 - loss: 1.5687 - val_accuracy: 0.3267 - val_loss: 1.5989\n",
      "Epoch 3/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.3318 - loss: 1.5728 - val_accuracy: 0.3267 - val_loss: 1.5918\n",
      "Epoch 4/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3407 - loss: 1.5698 - val_accuracy: 0.3267 - val_loss: 1.5941\n",
      "Epoch 5/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.3337 - loss: 1.5743 - val_accuracy: 0.3267 - val_loss: 1.5917\n",
      "Epoch 6/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.3393 - loss: 1.5737 - val_accuracy: 0.3267 - val_loss: 1.5933\n",
      "Epoch 7/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.3313 - loss: 1.5730 - val_accuracy: 0.3267 - val_loss: 1.5935\n",
      "Epoch 8/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3519 - loss: 1.5711 - val_accuracy: 0.3011 - val_loss: 1.5920\n",
      "Epoch 9/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.4077 - loss: 1.4986 - val_accuracy: 0.5289 - val_loss: 1.3042\n",
      "Epoch 10/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.5315 - loss: 1.2765 - val_accuracy: 0.5500 - val_loss: 1.1608\n",
      "Epoch 11/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5640 - loss: 1.1699 - val_accuracy: 0.5683 - val_loss: 1.0975\n",
      "Epoch 12/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5853 - loss: 1.0765 - val_accuracy: 0.6222 - val_loss: 0.9182\n",
      "Epoch 13/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.6320 - loss: 0.9420 - val_accuracy: 0.7356 - val_loss: 0.7359\n",
      "Epoch 14/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.6958 - loss: 0.8005 - val_accuracy: 0.7867 - val_loss: 0.5952\n",
      "Epoch 15/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.7457 - loss: 0.6916 - val_accuracy: 0.8200 - val_loss: 0.5006\n",
      "Epoch 16/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7709 - loss: 0.6276 - val_accuracy: 0.8222 - val_loss: 0.4757\n",
      "Epoch 17/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7909 - loss: 0.5720 - val_accuracy: 0.8528 - val_loss: 0.4240\n",
      "Epoch 18/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8190 - loss: 0.5063 - val_accuracy: 0.8761 - val_loss: 0.3742\n",
      "Epoch 19/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8296 - loss: 0.4657 - val_accuracy: 0.8856 - val_loss: 0.3381\n",
      "Epoch 20/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.8440 - loss: 0.4306 - val_accuracy: 0.8822 - val_loss: 0.3240\n",
      "Epoch 21/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.8475 - loss: 0.4049 - val_accuracy: 0.8939 - val_loss: 0.3156\n",
      "Epoch 22/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.8625 - loss: 0.3704 - val_accuracy: 0.8828 - val_loss: 0.2973\n",
      "Epoch 23/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8608 - loss: 0.3673 - val_accuracy: 0.8906 - val_loss: 0.2907\n",
      "Epoch 24/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8745 - loss: 0.3421 - val_accuracy: 0.8956 - val_loss: 0.2699\n",
      "Epoch 25/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8752 - loss: 0.3213 - val_accuracy: 0.8956 - val_loss: 0.2594\n",
      "Epoch 26/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8838 - loss: 0.3043 - val_accuracy: 0.9000 - val_loss: 0.2481\n",
      "Epoch 27/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.8891 - loss: 0.2900 - val_accuracy: 0.9072 - val_loss: 0.2408\n",
      "Epoch 28/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8897 - loss: 0.2897 - val_accuracy: 0.9028 - val_loss: 0.2524\n",
      "Epoch 29/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8970 - loss: 0.2692 - val_accuracy: 0.9011 - val_loss: 0.2384\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.8936 - loss: 0.2665 - val_accuracy: 0.8983 - val_loss: 0.2409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x141fabe7160>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(xtrain,ytrain,validation_split=0.1,epochs=30,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ed993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(xtest)\n",
    "predict = np.argmax(predict,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0a7f76a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94       610\n",
      "           1       0.96      0.88      0.92       639\n",
      "           2       0.76      0.81      0.78       168\n",
      "           3       0.90      0.90      0.90       271\n",
      "           4       0.86      0.93      0.89       240\n",
      "           5       0.89      0.76      0.82        72\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.88      0.87      0.88      2000\n",
      "weighted avg       0.91      0.90      0.90      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7c6004e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('emotion_analyzer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "75fe5cc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_9_1/embedding_9_1/GatherV2 defined at (most recent call last):\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n\n  File \"C:\\Users\\ANISH\\AppData\\Local\\Temp\\ipykernel_25752\\3886853127.py\", line 6, in <module>\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 560, in predict\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 259, in one_step_on_data_distributed\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 249, in one_step_on_data\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 104, in predict_step\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 910, in __call__\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 58, in __call__\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\models\\sequential.py\", line 221, in call\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 183, in call\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 643, in call\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 910, in __call__\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 58, in __call__\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 140, in call\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 5442, in take\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 2222, in take\n\nindices[0,13] = 1111110 is not in [0, 13738)\n\t [[{{node sequential_9_1/embedding_9_1/GatherV2}}]] [Op:__inference_one_step_on_data_distributed_379626]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m inp \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;241m441\u001b[39m, \u001b[38;5;241m3328\u001b[39m,    \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1179\u001b[39m,  \u001b[38;5;241m763\u001b[39m,   \u001b[38;5;241m17\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m      2\u001b[0m           \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m1111110\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m      3\u001b[0m           \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m      4\u001b[0m           \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m inp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(inp, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_9_1/embedding_9_1/GatherV2 defined at (most recent call last):\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n\n  File \"C:\\Users\\ANISH\\AppData\\Local\\Temp\\ipykernel_25752\\3886853127.py\", line 6, in <module>\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 560, in predict\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 259, in one_step_on_data_distributed\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 249, in one_step_on_data\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 104, in predict_step\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 910, in __call__\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 58, in __call__\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\models\\sequential.py\", line 221, in call\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 183, in call\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 643, in call\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 910, in __call__\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 58, in __call__\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 140, in call\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 5442, in take\n\n  File \"c:\\Nishanthi\\Hope_AI\\Projects\\Chat_Emotion_Detection\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 2222, in take\n\nindices[0,13] = 1111110 is not in [0, 13738)\n\t [[{{node sequential_9_1/embedding_9_1/GatherV2}}]] [Op:__inference_one_step_on_data_distributed_379626]"
     ]
    }
   ],
   "source": [
    "inp = [ 441, 3328,    1, 1179,  763,   17,    0,    0,    0,    0,    0,\n",
    "          0,    0,    1111110,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "          0,    0]\n",
    "inp = np.expand_dims(inp, axis=0).astype('int32')\n",
    "model.predict(inp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "90142423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 441, 3328,    1, 1179,  763,   17,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b9a1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
